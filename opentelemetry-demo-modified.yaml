apiVersion: v1
kind: Namespace
metadata:
  name: otel-demo
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/version: 2.19.0
  name: opensearch-pdb
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: opentelemetry-demo
      app.kubernetes.io/name: opensearch
---
apiVersion: v1
automountServiceAccountToken: false
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: grafana
    app.kubernetes.io/version: 11.5.2
  name: grafana
  namespace: otel-demo
---
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: all-in-one
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/version: 1.53.0
  name: jaeger
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: standalone-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/version: 0.120.0
  name: otel-collector
  namespace: otel-demo
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations: {}
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: prometheus
    app.kubernetes.io/version: v3.1.0
  name: prometheus
  namespace: otel-demo
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
  name: opentelemetry-demo
---
apiVersion: v1
data:
  admin-password: YWRtaW4=
  admin-user: YWRtaW4=
  ldap-toml: ''
kind: Secret
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: grafana
    app.kubernetes.io/version: 11.5.2
  name: grafana
  namespace: otel-demo
type: Opaque
---
apiVersion: v1
data:
  dashboardproviders.yaml: "apiVersion: 1\nproviders:\n- disableDeletion: false\n\
    \  editable: true\n  folder: \"\"\n  name: default\n  options:\n    path: /var/lib/grafana/dashboards/default\n\
    \  orgId: 1\n  type: file\n"
  datasources.yaml: "apiVersion: 1\ndatasources:\n- editable: true\n  isDefault: true\n\
    \  jsonData:\n    exemplarTraceIdDestinations:\n    - datasourceUid: webstore-traces\n\
    \      name: trace_id\n    - name: trace_id\n      url: http://localhost:8080/jaeger/ui/trace/$${__value.raw}\n\
    \      urlDisplayLabel: View in Jaeger UI\n  name: Prometheus\n  type: prometheus\n\
    \  uid: webstore-metrics\n  url: http://prometheus:9090\n- editable: true\n  isDefault:\
    \ false\n  name: Jaeger\n  type: jaeger\n  uid: webstore-traces\n  url: http://jaeger-query:16686/jaeger/ui\n\
    - access: proxy\n  editable: true\n  isDefault: false\n  jsonData:\n    database:\
    \ otel\n    flavor: opensearch\n    logLevelField: severity.text.keyword\n   \
    \ logMessageField: body\n    pplEnabled: true\n    timeField: observedTimestamp\n\
    \    version: 2.18.0\n  name: OpenSearch\n  type: grafana-opensearch-datasource\n\
    \  uid: webstore-logs\n  url: http://opensearch:9200/\n"
  grafana.ini: '[analytics]

    check_for_updates = true

    [auth]

    disable_login_form = true

    [auth.anonymous]

    enabled = true

    org_name = Main Org.

    org_role = Admin

    [grafana_net]

    url = https://grafana.net

    [log]

    mode = console

    [paths]

    data = /var/lib/grafana/

    logs = /var/log/grafana

    plugins = /var/lib/grafana/plugins

    provisioning = /etc/grafana/provisioning

    [server]

    domain = ''''

    root_url = %(protocol)s://%(domain)s:%(http_port)s/grafana

    serve_from_sub_path = true

    '
  plugins: grafana-opensearch-datasource
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: grafana
    app.kubernetes.io/version: 11.5.2
  name: grafana
  namespace: otel-demo
---
apiVersion: v1
data:
  opensearch.yml: 'cluster.name: opensearch-cluster


    # Bind to all interfaces because we don''t know what IP address Docker will assign
    to us.

    network.host: 0.0.0.0


    # Setting network.host to a non-loopback address enables the annoying bootstrap
    checks. "Single-node" mode disables them again.

    # Implicitly done if ".singleNode" is set to "true".

    # discovery.type: single-node


    # Start OpenSearch Security Demo Configuration

    # WARNING: revise all the lines below before you go into production

    # plugins:

    #   security:

    #     ssl:

    #       transport:

    #         pemcert_filepath: esnode.pem

    #         pemkey_filepath: esnode-key.pem

    #         pemtrustedcas_filepath: root-ca.pem

    #         enforce_hostname_verification: false

    #       http:

    #         enabled: true

    #         pemcert_filepath: esnode.pem

    #         pemkey_filepath: esnode-key.pem

    #         pemtrustedcas_filepath: root-ca.pem

    #     allow_unsafe_democertificates: true

    #     allow_default_init_securityindex: true

    #     authcz:

    #       admin_dn:

    #         - CN=kirk,OU=client,O=client,L=test,C=de

    #     audit.type: internal_opensearch

    #     enable_snapshot_restore_privilege: true

    #     check_snapshot_restore_write_privileges: true

    #     restapi:

    #       roles_enabled: ["all_access", "security_rest_api_access"]

    #     system_indices:

    #       enabled: true

    #       indices:

    #         [

    #           ".opendistro-alerting-config",

    #           ".opendistro-alerting-alert*",

    #           ".opendistro-anomaly-results*",

    #           ".opendistro-anomaly-detector*",

    #           ".opendistro-anomaly-checkpoints",

    #           ".opendistro-anomaly-detection-state",

    #           ".opendistro-reports-*",

    #           ".opendistro-notifications-*",

    #           ".opendistro-notebooks",

    #           ".opendistro-asynchronous-search-response*",

    #         ]

    ######## End OpenSearch Security Demo Configuration ########

    '
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/version: 2.19.0
  name: opensearch-config
---
apiVersion: v1
data:
  relay: "connectors:\n  spanmetrics: {}\nexporters:\n  debug: {}\n  opensearch:\n\
    \    http:\n      endpoint: http://opensearch:9200\n      tls:\n        insecure:\
    \ true\n    logs_index: otel\n  otlp:\n    endpoint: jaeger-collector:4317\n \
    \   tls:\n      insecure: true\n  otlphttp/prometheus:\n    endpoint: http://prometheus:9090/api/v1/otlp\n\
    \    tls:\n      insecure: true\nextensions:\n  health_check:\n    endpoint: ${env:MY_POD_IP}:13133\n\
    processors:\n  batch: {}\n  k8sattributes:\n    extract:\n      metadata:\n  \
    \    - k8s.namespace.name\n      - k8s.deployment.name\n      - k8s.statefulset.name\n\
    \      - k8s.daemonset.name\n      - k8s.cronjob.name\n      - k8s.job.name\n\
    \      - k8s.node.name\n      - k8s.pod.name\n      - k8s.pod.uid\n      - k8s.pod.start_time\n\
    \    passthrough: false\n    pod_association:\n    - sources:\n      - from: resource_attribute\n\
    \        name: k8s.pod.ip\n    - sources:\n      - from: resource_attribute\n\
    \        name: k8s.pod.uid\n    - sources:\n      - from: connection\n  memory_limiter:\n\
    \    check_interval: 5s\n    limit_percentage: 80\n    spike_limit_percentage:\
    \ 25\n  resource:\n    attributes:\n    - action: insert\n      from_attribute:\
    \ k8s.pod.uid\n      key: service.instance.id\n  transform:\n    error_mode: ignore\n\
    \    trace_statements:\n    - context: span\n      statements:\n      - replace_pattern(name,\
    \ \"\\\\?.*\", \"\")\n      - replace_match(name, \"GET /api/products/*\", \"\
    GET /api/products/{productId}\")\nreceivers:\n  httpcheck/frontend-proxy:\n  \
    \  targets:\n    - endpoint: http://frontend-proxy:8080\n  jaeger:\n    protocols:\n\
    \      grpc:\n        endpoint: ${env:MY_POD_IP}:14250\n      thrift_compact:\n\
    \        endpoint: ${env:MY_POD_IP}:6831\n      thrift_http:\n        endpoint:\
    \ ${env:MY_POD_IP}:14268\n  otlp:\n    protocols:\n      grpc:\n        endpoint:\
    \ ${env:MY_POD_IP}:4317\n      http:\n        cors:\n          allowed_origins:\n\
    \          - http://*\n          - https://*\n        endpoint: ${env:MY_POD_IP}:4318\n\
    \  prometheus:\n    config:\n      scrape_configs:\n      - job_name: opentelemetry-collector\n\
    \        scrape_interval: 10s\n        static_configs:\n        - targets:\n \
    \         - ${env:MY_POD_IP}:8888\n  redis:\n    collection_interval: 10s\n  \
    \  endpoint: valkey-cart:6379\n  zipkin:\n    endpoint: ${env:MY_POD_IP}:9411\n\
    service:\n  extensions:\n  - health_check\n  pipelines:\n    logs:\n      exporters:\n\
    \      - opensearch\n      - debug\n      processors:\n      - k8sattributes\n\
    \      - memory_limiter\n      - resource\n      - batch\n      receivers:\n \
    \     - otlp\n    metrics:\n      exporters:\n      - otlphttp/prometheus\n  \
    \    - debug\n      processors:\n      - k8sattributes\n      - memory_limiter\n\
    \      - resource\n      - batch\n      receivers:\n      - httpcheck/frontend-proxy\n\
    \      - redis\n      - otlp\n      - spanmetrics\n    traces:\n      exporters:\n\
    \      - otlp\n      - debug\n      - spanmetrics\n      processors:\n      -\
    \ k8sattributes\n      - memory_limiter\n      - resource\n      - transform\n\
    \      - batch\n      receivers:\n      - otlp\n      - jaeger\n      - zipkin\n\
    \  telemetry:\n    metrics:\n      address: ${env:MY_POD_IP}:8888\n      level:\
    \ detailed\n      readers:\n      - periodic:\n          exporter:\n         \
    \   otlp:\n              endpoint: otel-collector:4318\n              protocol:\
    \ grpc\n          interval: 10000\n          timeout: 5000\n"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: standalone-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/version: 0.120.0
  name: otel-collector
  namespace: otel-demo
---
apiVersion: v1
data:
  alerting_rules.yml: '{}

    '
  alerts: '{}

    '
  allow-snippet-annotations: 'false'
  prometheus.yml: "global:\n  evaluation_interval: 30s\n  scrape_interval: 5s\n  scrape_timeout:\
    \ 3s\nstorage:\n  tsdb:\n    out_of_order_time_window: 30m\nrule_files:\n- /etc/config/recording_rules.yml\n\
    - /etc/config/alerting_rules.yml\n- /etc/config/rules\n- /etc/config/alerts\n\
    scrape_configs:\n- job_name: prometheus\n  static_configs:\n  - targets:\n   \
    \ - localhost:9090\n- bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\
    \  job_name: kubernetes-apiservers\n  kubernetes_sd_configs:\n  - role: endpoints\n\
    \  relabel_configs:\n  - action: keep\n    regex: default;kubernetes;https\n \
    \   source_labels:\n    - __meta_kubernetes_namespace\n    - __meta_kubernetes_service_name\n\
    \    - __meta_kubernetes_endpoint_port_name\n  scheme: https\n  tls_config:\n\
    \    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n- bearer_token_file:\
    \ /var/run/secrets/kubernetes.io/serviceaccount/token\n  job_name: kubernetes-nodes\n\
    \  kubernetes_sd_configs:\n  - role: node\n  relabel_configs:\n  - action: labelmap\n\
    \    regex: __meta_kubernetes_node_label_(.+)\n  - replacement: kubernetes.default.svc:443\n\
    \    target_label: __address__\n  - regex: (.+)\n    replacement: /api/v1/nodes/$1/proxy/metrics\n\
    \    source_labels:\n    - __meta_kubernetes_node_name\n    target_label: __metrics_path__\n\
    \  scheme: https\n  tls_config:\n    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n\
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n  job_name:\
    \ kubernetes-nodes-cadvisor\n  kubernetes_sd_configs:\n  - role: node\n  relabel_configs:\n\
    \  - action: labelmap\n    regex: __meta_kubernetes_node_label_(.+)\n  - replacement:\
    \ kubernetes.default.svc:443\n    target_label: __address__\n  - regex: (.+)\n\
    \    replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor\n    source_labels:\n\
    \    - __meta_kubernetes_node_name\n    target_label: __metrics_path__\n  scheme:\
    \ https\n  tls_config:\n    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n\
    - honor_labels: true\n  job_name: kubernetes-service-endpoints\n  kubernetes_sd_configs:\n\
    \  - role: endpoints\n  relabel_configs:\n  - action: keep\n    regex: true\n\
    \    source_labels:\n    - __meta_kubernetes_service_annotation_prometheus_io_scrape\n\
    \  - action: drop\n    regex: true\n    source_labels:\n    - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow\n\
    \  - action: replace\n    regex: (https?)\n    source_labels:\n    - __meta_kubernetes_service_annotation_prometheus_io_scheme\n\
    \    target_label: __scheme__\n  - action: replace\n    regex: (.+)\n    source_labels:\n\
    \    - __meta_kubernetes_service_annotation_prometheus_io_path\n    target_label:\
    \ __metrics_path__\n  - action: replace\n    regex: (.+?)(?::\\d+)?;(\\d+)\n \
    \   replacement: $1:$2\n    source_labels:\n    - __address__\n    - __meta_kubernetes_service_annotation_prometheus_io_port\n\
    \    target_label: __address__\n  - action: labelmap\n    regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)\n\
    \    replacement: __param_$1\n  - action: labelmap\n    regex: __meta_kubernetes_service_label_(.+)\n\
    \  - action: replace\n    source_labels:\n    - __meta_kubernetes_namespace\n\
    \    target_label: namespace\n  - action: replace\n    source_labels:\n    - __meta_kubernetes_service_name\n\
    \    target_label: service\n  - action: replace\n    source_labels:\n    - __meta_kubernetes_pod_node_name\n\
    \    target_label: node\n- honor_labels: true\n  job_name: kubernetes-service-endpoints-slow\n\
    \  kubernetes_sd_configs:\n  - role: endpoints\n  relabel_configs:\n  - action:\
    \ keep\n    regex: true\n    source_labels:\n    - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow\n\
    \  - action: replace\n    regex: (https?)\n    source_labels:\n    - __meta_kubernetes_service_annotation_prometheus_io_scheme\n\
    \    target_label: __scheme__\n  - action: replace\n    regex: (.+)\n    source_labels:\n\
    \    - __meta_kubernetes_service_annotation_prometheus_io_path\n    target_label:\
    \ __metrics_path__\n  - action: replace\n    regex: (.+?)(?::\\d+)?;(\\d+)\n \
    \   replacement: $1:$2\n    source_labels:\n    - __address__\n    - __meta_kubernetes_service_annotation_prometheus_io_port\n\
    \    target_label: __address__\n  - action: labelmap\n    regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)\n\
    \    replacement: __param_$1\n  - action: labelmap\n    regex: __meta_kubernetes_service_label_(.+)\n\
    \  - action: replace\n    source_labels:\n    - __meta_kubernetes_namespace\n\
    \    target_label: namespace\n  - action: replace\n    source_labels:\n    - __meta_kubernetes_service_name\n\
    \    target_label: service\n  - action: replace\n    source_labels:\n    - __meta_kubernetes_pod_node_name\n\
    \    target_label: node\n  scrape_interval: 5m\n  scrape_timeout: 30s\n- honor_labels:\
    \ true\n  job_name: prometheus-pushgateway\n  kubernetes_sd_configs:\n  - role:\
    \ service\n  relabel_configs:\n  - action: keep\n    regex: pushgateway\n    source_labels:\n\
    \    - __meta_kubernetes_service_annotation_prometheus_io_probe\n- honor_labels:\
    \ true\n  job_name: kubernetes-services\n  kubernetes_sd_configs:\n  - role: service\n\
    \  metrics_path: /probe\n  params:\n    module:\n    - http_2xx\n  relabel_configs:\n\
    \  - action: keep\n    regex: true\n    source_labels:\n    - __meta_kubernetes_service_annotation_prometheus_io_probe\n\
    \  - source_labels:\n    - __address__\n    target_label: __param_target\n  -\
    \ replacement: blackbox\n    target_label: __address__\n  - source_labels:\n \
    \   - __param_target\n    target_label: instance\n  - action: labelmap\n    regex:\
    \ __meta_kubernetes_service_label_(.+)\n  - source_labels:\n    - __meta_kubernetes_namespace\n\
    \    target_label: namespace\n  - source_labels:\n    - __meta_kubernetes_service_name\n\
    \    target_label: service\n- honor_labels: true\n  job_name: kubernetes-pods\n\
    \  kubernetes_sd_configs:\n  - role: pod\n  relabel_configs:\n  - action: keep\n\
    \    regex: true\n    source_labels:\n    - __meta_kubernetes_pod_annotation_prometheus_io_scrape\n\
    \  - action: drop\n    regex: true\n    source_labels:\n    - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow\n\
    \  - action: replace\n    regex: (https?)\n    source_labels:\n    - __meta_kubernetes_pod_annotation_prometheus_io_scheme\n\
    \    target_label: __scheme__\n  - action: replace\n    regex: (.+)\n    source_labels:\n\
    \    - __meta_kubernetes_pod_annotation_prometheus_io_path\n    target_label:\
    \ __metrics_path__\n  - action: replace\n    regex: (\\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})\n\
    \    replacement: '[$2]:$1'\n    source_labels:\n    - __meta_kubernetes_pod_annotation_prometheus_io_port\n\
    \    - __meta_kubernetes_pod_ip\n    target_label: __address__\n  - action: replace\n\
    \    regex: (\\d+);((([0-9]+?)(\\.|$)){4})\n    replacement: $2:$1\n    source_labels:\n\
    \    - __meta_kubernetes_pod_annotation_prometheus_io_port\n    - __meta_kubernetes_pod_ip\n\
    \    target_label: __address__\n  - action: labelmap\n    regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)\n\
    \    replacement: __param_$1\n  - action: labelmap\n    regex: __meta_kubernetes_pod_label_(.+)\n\
    \  - action: replace\n    source_labels:\n    - __meta_kubernetes_namespace\n\
    \    target_label: namespace\n  - action: replace\n    source_labels:\n    - __meta_kubernetes_pod_name\n\
    \    target_label: pod\n  - action: drop\n    regex: Pending|Succeeded|Failed|Completed\n\
    \    source_labels:\n    - __meta_kubernetes_pod_phase\n  - action: replace\n\
    \    source_labels:\n    - __meta_kubernetes_pod_node_name\n    target_label:\
    \ node\n- honor_labels: true\n  job_name: kubernetes-pods-slow\n  kubernetes_sd_configs:\n\
    \  - role: pod\n  relabel_configs:\n  - action: keep\n    regex: true\n    source_labels:\n\
    \    - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow\n  - action:\
    \ replace\n    regex: (https?)\n    source_labels:\n    - __meta_kubernetes_pod_annotation_prometheus_io_scheme\n\
    \    target_label: __scheme__\n  - action: replace\n    regex: (.+)\n    source_labels:\n\
    \    - __meta_kubernetes_pod_annotation_prometheus_io_path\n    target_label:\
    \ __metrics_path__\n  - action: replace\n    regex: (\\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})\n\
    \    replacement: '[$2]:$1'\n    source_labels:\n    - __meta_kubernetes_pod_annotation_prometheus_io_port\n\
    \    - __meta_kubernetes_pod_ip\n    target_label: __address__\n  - action: replace\n\
    \    regex: (\\d+);((([0-9]+?)(\\.|$)){4})\n    replacement: $2:$1\n    source_labels:\n\
    \    - __meta_kubernetes_pod_annotation_prometheus_io_port\n    - __meta_kubernetes_pod_ip\n\
    \    target_label: __address__\n  - action: labelmap\n    regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)\n\
    \    replacement: __param_$1\n  - action: labelmap\n    regex: __meta_kubernetes_pod_label_(.+)\n\
    \  - action: replace\n    source_labels:\n    - __meta_kubernetes_namespace\n\
    \    target_label: namespace\n  - action: replace\n    source_labels:\n    - __meta_kubernetes_pod_name\n\
    \    target_label: pod\n  - action: drop\n    regex: Pending|Succeeded|Failed|Completed\n\
    \    source_labels:\n    - __meta_kubernetes_pod_phase\n  - action: replace\n\
    \    source_labels:\n    - __meta_kubernetes_pod_node_name\n    target_label:\
    \ node\n  scrape_interval: 5m\n  scrape_timeout: 30s\n"
  recording_rules.yml: '{}

    '
  rules: '{}

    '
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: prometheus
    app.kubernetes.io/version: v3.1.0
  name: prometheus
  namespace: otel-demo
---
apiVersion: v1
data:
  demo.flagd.json: "{\n  \"$schema\": \"https://flagd.dev/schema/v0/flags.json\",\n\
    \  \"flags\": {\n    \"productCatalogFailure\": {\n      \"description\": \"Fail\
    \ product catalog service on a specific product\",\n      \"state\": \"ENABLED\"\
    ,\n      \"variants\": {\n        \"on\": true,\n        \"off\": false\n    \
    \  },\n      \"defaultVariant\": \"off\"\n    },\n    \"recommendationCacheFailure\"\
    : {\n      \"description\": \"Fail recommendation service cache\",\n      \"state\"\
    : \"ENABLED\",\n      \"variants\": {\n        \"on\": true,\n        \"off\"\
    : false\n      },\n      \"defaultVariant\": \"off\"\n    },\n    \"adManualGc\"\
    : {\n      \"description\": \"Triggers full manual garbage collections in the\
    \ ad service\",\n      \"state\": \"ENABLED\",\n      \"variants\": {\n      \
    \  \"on\": true,\n        \"off\": false\n      },\n      \"defaultVariant\":\
    \ \"off\"\n    },\n    \"adHighCpu\": {\n      \"description\": \"Triggers high\
    \ cpu load in the ad service\",\n      \"state\": \"ENABLED\",\n      \"variants\"\
    : {\n        \"on\": true,\n        \"off\": false\n      },\n      \"defaultVariant\"\
    : \"off\"\n    },\n    \"adFailure\": {\n      \"description\": \"Fail ad service\"\
    ,\n      \"state\": \"ENABLED\",\n      \"variants\": {\n        \"on\": true,\n\
    \        \"off\": false\n      },\n      \"defaultVariant\": \"off\"\n    },\n\
    \    \"kafkaQueueProblems\": {\n      \"description\": \"Overloads Kafka queue\
    \ while simultaneously introducing a consumer side delay leading to a lag spike\"\
    ,\n      \"state\": \"ENABLED\",\n      \"variants\": {\n        \"on\": 100,\n\
    \        \"off\": 0\n      },\n      \"defaultVariant\": \"off\"\n    },\n   \
    \ \"cartFailure\": {\n      \"description\": \"Fail cart service\",\n      \"\
    state\": \"ENABLED\",\n      \"variants\": {\n        \"on\": true,\n        \"\
    off\": false\n      },\n      \"defaultVariant\": \"off\"\n    },\n    \"paymentFailure\"\
    : {\n      \"description\": \"Fail payment service charge requests n%\",\n   \
    \   \"state\": \"ENABLED\",\n      \"variants\": {\n        \"100%\": 1,\n   \
    \     \"90%\": 0.95,\n        \"75%\": 0.75,\n        \"50%\": 0.5,\n        \"\
    25%\": 0.25,\n        \"10%\": 0.1,\n        \"off\": 0\n      },\n      \"defaultVariant\"\
    : \"off\"\n    },\n    \"paymentUnreachable\": {\n      \"description\": \"Payment\
    \ service is unavailable\",\n      \"state\": \"ENABLED\",\n      \"variants\"\
    : {\n        \"on\": true,\n        \"off\": false\n      },\n      \"defaultVariant\"\
    : \"off\"\n    },\n    \"loadGeneratorFloodHomepage\": {\n      \"description\"\
    : \"Flood the frontend with a large amount of requests.\",\n      \"state\": \"\
    ENABLED\",\n      \"variants\": {\n        \"on\": 100,\n        \"off\": 0\n\
    \      },\n      \"defaultVariant\": \"off\"\n    },\n    \"imageSlowLoad\": {\n\
    \      \"description\": \"slow loading images in the frontend\",\n      \"state\"\
    : \"ENABLED\",\n      \"variants\": {\n        \"10sec\": 10000,\n        \"5sec\"\
    : 5000,\n        \"off\": 0\n      },\n      \"defaultVariant\": \"off\"\n   \
    \ }\n  }\n}\n"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
  name: flagd-config
  namespace: otel-demo
---
apiVersion: v1
data:
  products.json: "{\n  \"products\": [\n    {\n      \"id\": \"OLJCESPC7Z\",\n   \
    \   \"name\": \"National Park Foundation Explorascope\",\n      \"description\"\
    : \"The National Park Foundation\u2019s (NPF) Explorascope 60AZ is a manual alt-azimuth,\
    \ refractor telescope perfect for celestial viewing on the go. The NPF Explorascope\
    \ 60 can view the planets, moon, star clusters and brighter deep sky objects like\
    \ the Orion Nebula and Andromeda Galaxy.\",\n      \"picture\": \"NationalParkFoundationExplorascope.jpg\"\
    ,\n      \"priceUsd\": {\n        \"currencyCode\": \"USD\",\n        \"units\"\
    : 101,\n        \"nanos\": 960000000\n      },\n      \"categories\": [\n    \
    \    \"telescopes\"\n      ]\n    },\n    {\n      \"id\": \"66VCHSJNUP\",\n \
    \     \"name\": \"Starsense Explorer Refractor Telescope\",\n      \"description\"\
    : \"The first telescope that uses your smartphone to analyze the night sky and\
    \ calculate its position in real time. StarSense Explorer is ideal for beginners\
    \ thanks to the app\u2019s user-friendly interface and detailed tutorials. It\u2019\
    s like having your own personal tour guide of the night sky\",\n      \"picture\"\
    : \"StarsenseExplorer.jpg\",\n      \"priceUsd\": {\n        \"currencyCode\"\
    : \"USD\",\n        \"units\": 349,\n        \"nanos\": 950000000\n      },\n\
    \      \"categories\": [\n        \"telescopes\"\n      ]\n    },\n    {\n   \
    \   \"id\": \"1YMWWN1N4O\",\n      \"name\": \"Eclipsmart Travel Refractor Telescope\"\
    ,\n      \"description\": \"Dedicated white-light solar scope for the observer\
    \ on the go. The 50mm refracting solar scope uses Solar Safe, ISO compliant, full-aperture\
    \ glass filter material to ensure the safest view of solar events.  The kit comes\
    \ complete with everything you need, including the dedicated travel solar scope,\
    \ a Solar Safe finderscope, tripod, a high quality 20mm (18x) Kellner eyepiece\
    \ and a nylon backpack to carry everything in.  This Travel Solar Scope makes\
    \ it easy to share the Sun as well as partial and total solar eclipses with the\
    \ whole family and offers much higher magnifications than you would otherwise\
    \ get using handheld solar viewers or binoculars.\",\n      \"picture\": \"EclipsmartTravelRefractorTelescope.jpg\"\
    ,\n      \"priceUsd\": {\n        \"currencyCode\": \"USD\",\n        \"units\"\
    : 129,\n        \"nanos\": 950000000\n      },\n      \"categories\": [\n    \
    \    \"telescopes\",\n        \"travel\"\n      ]\n    },\n    {\n      \"id\"\
    : \"L9ECAV7KIM\",\n      \"name\": \"Lens Cleaning Kit\",\n      \"description\"\
    : \"Wipe away dust, dirt, fingerprints and other particles on your lenses to see\
    \ clearly with the Lens Cleaning Kit. This cleaning kit works on all glass and\
    \ optical surfaces, including telescopes, binoculars, spotting scopes, monoculars,\
    \ microscopes, and even your camera lenses, computer screens, and mobile devices.\
    \  The kit comes complete with a retractable lens brush to remove dust particles\
    \ and dirt and two options to clean smudges and fingerprints off of your optics,\
    \ pre-moistened lens wipes and a bottled lens cleaning fluid with soft cloth.\"\
    ,\n      \"picture\": \"LensCleaningKit.jpg\",\n      \"priceUsd\": {\n      \
    \  \"currencyCode\": \"USD\",\n        \"units\": 21,\n        \"nanos\": 950000000\n\
    \      },\n      \"categories\": [\n        \"accessories\"\n      ]\n    },\n\
    \    {\n      \"id\": \"2ZYFJ3GM2N\",\n      \"name\": \"Roof Binoculars\",\n\
    \      \"description\": \"This versatile, all-around binocular is a great choice\
    \ for the trail, the stadium, the arena, or just about anywhere you want a close-up\
    \ view of the action without sacrificing brightness or detail. It\u2019s an especially\
    \ great companion for nature observation and bird watching, with ED glass that\
    \ helps you spot the subtlest field markings and a close focus of just 6.5 feet.\"\
    ,\n      \"picture\": \"RoofBinoculars.jpg\",\n      \"priceUsd\": {\n       \
    \ \"currencyCode\": \"USD\",\n        \"units\": 209,\n        \"nanos\": 950000000\n\
    \      },\n      \"categories\": [\n        \"binoculars\"\n      ]\n    },\n\
    \    {\n      \"id\": \"0PUK6V6EV0\",\n      \"name\": \"Solar System Color Imager\"\
    ,\n      \"description\": \"You have your new telescope and have observed Saturn\
    \ and Jupiter. Now you're ready to take the next step and start imaging them.\
    \ But where do you begin? The NexImage 10 Solar System Imager is the perfect solution.\"\
    ,\n      \"picture\": \"SolarSystemColorImager.jpg\",\n      \"priceUsd\": {\n\
    \        \"currencyCode\": \"USD\",\n        \"units\": 175,\n        \"nanos\"\
    : 0\n      },\n      \"categories\": [\n        \"accessories\",\n        \"telescopes\"\
    \n      ]\n    },\n    {\n      \"id\": \"LS4PSXUNUM\",\n      \"name\": \"Red\
    \ Flashlight\",\n      \"description\": \"This 3-in-1 device features a 3-mode\
    \ red flashlight, a hand warmer, and a portable power bank for recharging your\
    \ personal electronics on the go. Whether you use it to light the way at an astronomy\
    \ star party, a night walk, or wildlife research, ThermoTorch 3 Astro Red\u2019\
    s rugged, IPX4-rated design will withstand your everyday activities.\",\n    \
    \  \"picture\": \"RedFlashlight.jpg\",\n      \"priceUsd\": {\n        \"currencyCode\"\
    : \"USD\",\n        \"units\": 57,\n        \"nanos\": 80000000\n      },\n  \
    \    \"categories\": [\n        \"accessories\",\n        \"flashlights\"\n  \
    \    ]\n    },\n    {\n      \"id\": \"9SIQT8TOJO\",\n      \"name\": \"Optical\
    \ Tube Assembly\",\n      \"description\": \"Capturing impressive deep-sky astroimages\
    \ is easier than ever with Rowe-Ackermann Schmidt Astrograph (RASA) V2, the perfect\
    \ companion to today\u2019s top DSLR or astronomical CCD cameras. This fast, wide-field\
    \ f/2.2 system allows for shorter exposure times compared to traditional f/10\
    \ astroimaging, without sacrificing resolution. Because shorter sub-exposure times\
    \ are possible, your equatorial mount won\u2019t need to accurately track over\
    \ extended periods. The short focal length also lessens equatorial tracking demands.\
    \ In many cases, autoguiding will not be required.\",\n      \"picture\": \"OpticalTubeAssembly.jpg\"\
    ,\n      \"priceUsd\": {\n        \"currencyCode\": \"USD\",\n        \"units\"\
    : 3599,\n        \"nanos\": 0\n      },\n      \"categories\": [\n        \"accessories\"\
    ,\n        \"telescopes\",\n        \"assembly\"\n      ]\n    },\n    {\n   \
    \   \"id\": \"6E92ZMYYFZ\",\n      \"name\": \"Solar Filter\",\n      \"description\"\
    : \"Enhance your viewing experience with EclipSmart Solar Filter for 8\u201D telescopes.\
    \ With two Velcro straps and four self-adhesive Velcro pads for added safety,\
    \ you can be assured that the solar filter cannot be accidentally knocked off\
    \ and will provide Solar Safe, ISO compliant viewing.\",\n      \"picture\": \"\
    SolarFilter.jpg\",\n      \"priceUsd\": {\n        \"currencyCode\": \"USD\",\n\
    \        \"units\": 69,\n        \"nanos\": 950000000\n      },\n      \"categories\"\
    : [\n        \"accessories\",\n        \"telescopes\"\n      ]\n    },\n    {\n\
    \      \"id\": \"HQTGWGPNH4\",\n      \"name\": \"The Comet Book\",\n      \"\
    description\": \"A 16th-century treatise on comets, created anonymously in Flanders\
    \ (now northern France) and now held at the Universit\xE4tsbibliothek Kassel.\
    \ Commonly known as The Comet Book (or Kometenbuch in German), its full title\
    \ translates as \u201CComets and their General and Particular Meanings, According\
    \ to Ptolome\xE9, Albumasar, Haly, Aliquind and other Astrologers\u201D. The image\
    \ is from https://publicdomainreview.org/collection/the-comet-book, made available\
    \ by the Universit\xE4tsbibliothek Kassel under a CC-BY SA 4.0 license (https://creativecommons.org/licenses/by-sa/4.0/)\"\
    ,\n      \"picture\": \"TheCometBook.jpg\",\n      \"priceUsd\": {\n        \"\
    currencyCode\": \"USD\",\n        \"units\": 0,\n        \"nanos\": 990000000\n\
    \      },\n      \"categories\": [\n        \"books\"\n      ]\n    }\n  ]\n}\n"
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
  name: product-catalog-products
  namespace: otel-demo
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: grafana
    app.kubernetes.io/version: 11.5.2
  name: grafana-clusterrole
rules: []
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: standalone-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/version: 0.120.0
  name: otel-collector
rules:
- apiGroups:
  - ''
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - watch
  - list
- apiGroups:
  - apps
  resources:
  - replicasets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - replicasets
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: prometheus
    app.kubernetes.io/version: v3.1.0
  name: prometheus
rules:
- apiGroups:
  - ''
  resources:
  - nodes
  - nodes/proxy
  - nodes/metrics
  - services
  - endpoints
  - pods
  - ingresses
  - configmaps
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  - networking.k8s.io
  resources:
  - ingresses/status
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - discovery.k8s.io
  resources:
  - endpointslices
  verbs:
  - get
  - list
  - watch
- nonResourceURLs:
  - /metrics
  verbs:
  - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: grafana
    app.kubernetes.io/version: 11.5.2
  name: grafana-clusterrolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: grafana-clusterrole
subjects:
- kind: ServiceAccount
  name: grafana
  namespace: otel-demo
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: standalone-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/version: 0.120.0
  name: otel-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-collector
subjects:
- kind: ServiceAccount
  name: otel-collector
  namespace: otel-demo
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: prometheus
    app.kubernetes.io/version: v3.1.0
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: otel-demo
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: grafana
    app.kubernetes.io/version: 11.5.2
  name: grafana
  namespace: otel-demo
rules: []
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: grafana
    app.kubernetes.io/version: 11.5.2
  name: grafana
  namespace: otel-demo
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: grafana
subjects:
- kind: ServiceAccount
  name: grafana
  namespace: otel-demo
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: grafana
    app.kubernetes.io/version: 11.5.2
  name: grafana
  namespace: otel-demo
spec:
  ports:
  - name: service
    port: 80
    protocol: TCP
    targetPort: 3000
  selector:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: grafana
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: service-agent
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/version: 1.53.0
  name: jaeger-agent
spec:
  clusterIP: None
  ports:
  - name: zk-compact-trft
    port: 5775
    protocol: UDP
    targetPort: 0
  - name: config-rest
    port: 5778
    targetPort: 0
  - name: jg-compact-trft
    port: 6831
    protocol: UDP
    targetPort: 0
  - name: jg-binary-trft
    port: 6832
    protocol: UDP
    targetPort: 0
  selector:
    app.kubernetes.io/component: all-in-one
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: jaeger
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: service-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/version: 1.53.0
  name: jaeger-collector
spec:
  clusterIP: None
  ports:
  - appProtocol: http
    name: http-zipkin
    port: 9411
    targetPort: 0
  - appProtocol: grpc
    name: grpc-http
    port: 14250
    targetPort: 0
  - name: c-tchan-trft
    port: 14267
    targetPort: 0
  - appProtocol: http
    name: http-c-binary-trft
    port: 14268
    targetPort: 0
  - appProtocol: grpc
    name: otlp-grpc
    port: 4317
    targetPort: 0
  - appProtocol: http
    name: otlp-http
    port: 4318
    targetPort: 0
  selector:
    app.kubernetes.io/component: all-in-one
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: jaeger
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: service-query
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/version: 1.53.0
  name: jaeger-query
spec:
  clusterIP: None
  ports:
  - name: http-query
    port: 16686
    targetPort: 16686
  - name: grpc-query
    port: 16685
    targetPort: 16685
  selector:
    app.kubernetes.io/component: all-in-one
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: jaeger
---
apiVersion: v1
kind: Service
metadata:
  annotations: {}
  labels:
    app.kubernetes.io/component: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/version: 2.19.0
  name: opensearch
spec:
  ports:
  - name: http
    port: 9200
    protocol: TCP
  - name: transport
    port: 9300
    protocol: TCP
  - name: metrics
    port: 9600
    protocol: TCP
  selector:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opensearch
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: 'true'
  labels:
    app.kubernetes.io/component: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/version: 2.19.0
  name: opensearch-headless
spec:
  clusterIP: None
  ports:
  - name: http
    port: 9200
  - name: transport
    port: 9300
  - name: metrics
    port: 9600
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opensearch
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: standalone-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/version: 0.120.0
    component: standalone-collector
  name: otel-collector
  namespace: otel-demo
spec:
  internalTrafficPolicy: Cluster
  ports:
  - name: jaeger-compact
    port: 6831
    protocol: UDP
    targetPort: 6831
  - name: jaeger-grpc
    port: 14250
    protocol: TCP
    targetPort: 14250
  - name: jaeger-thrift
    port: 14268
    protocol: TCP
    targetPort: 14268
  - name: metrics
    port: 8888
    protocol: TCP
    targetPort: 8888
  - appProtocol: grpc
    name: otlp
    port: 4317
    protocol: TCP
    targetPort: 4317
  - name: otlp-http
    port: 4318
    protocol: TCP
    targetPort: 4318
  - name: zipkin
    port: 9411
    protocol: TCP
    targetPort: 9411
  selector:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opentelemetry-collector
    component: standalone-collector
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: prometheus
    app.kubernetes.io/version: v3.1.0
  name: prometheus
  namespace: otel-demo
spec:
  ports:
  - name: http
    port: 9090
    protocol: TCP
    targetPort: 9090
  selector:
    app.kubernetes.io/component: server
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: prometheus
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: ad
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: ad
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: ad
  name: ad
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: ad
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: cart
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: cart
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: cart
  name: cart
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: cart
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: checkout
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: checkout
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: checkout
  name: checkout
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: checkout
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: currency
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: currency
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: currency
  name: currency
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: currency
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: email
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: email
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: email
  name: email
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: email
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: flagd
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: flagd
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: flagd
  name: flagd
spec:
  ports:
  - name: rpc
    port: 8013
    targetPort: 8013
  - name: ofrep
    port: 8016
    targetPort: 8016
  - name: tcp-service-0
    port: 4000
    targetPort: 4000
  selector:
    opentelemetry.io/name: flagd
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: frontend
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: frontend
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: frontend
  name: frontend
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: frontend
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: frontend-proxy
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: frontend-proxy
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: frontend-proxy
  name: frontend-proxy
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: frontend-proxy
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: image-provider
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: image-provider
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: image-provider
  name: image-provider
spec:
  ports:
  - name: tcp-service
    port: 8081
    targetPort: 8081
  selector:
    opentelemetry.io/name: image-provider
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: kafka
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: kafka
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: kafka
  name: kafka
spec:
  ports:
  - name: plaintext
    port: 9092
    targetPort: 9092
  - name: controller
    port: 9093
    targetPort: 9093
  selector:
    opentelemetry.io/name: kafka
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: load-generator
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: load-generator
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: load-generator
  name: load-generator
spec:
  ports:
  - name: tcp-service
    port: 8089
    targetPort: 8089
  selector:
    opentelemetry.io/name: load-generator
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: payment
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: payment
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: payment
  name: payment
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: payment
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: product-catalog
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: product-catalog
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: product-catalog
  name: product-catalog
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: product-catalog
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: quote
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: quote
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: quote
  name: quote
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: quote
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: recommendation
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: recommendation
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: recommendation
  name: recommendation
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: recommendation
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: shipping
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: shipping
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: shipping
  name: shipping
spec:
  ports:
  - name: tcp-service
    port: 8080
    targetPort: 8080
  selector:
    opentelemetry.io/name: shipping
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: valkey-cart
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: valkey-cart
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: valkey-cart
  name: valkey-cart
spec:
  ports:
  - name: valkey-cart
    port: 6379
    targetPort: 6379
  selector:
    opentelemetry.io/name: valkey-cart
  type: ClusterIP
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: grafana
    app.kubernetes.io/version: 11.5.2
  name: grafana
  namespace: otel-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: opentelemetry-demo
      app.kubernetes.io/name: grafana
  strategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: 99cca986c6d5f6511900d815ee5a70d0c284aeb70af56fb96108c7bf456eff87
        checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
        checksum/secret: bed677784356b2af7fb0d87455db21f077853059b594101a4f6532bfbd962a7f
        kubectl.kubernetes.io/default-container: grafana
      labels:
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: grafana
        app.kubernetes.io/version: 11.5.2
    spec:
      automountServiceAccountToken: true
      containers:
      - env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: GF_SECURITY_ADMIN_USER
          valueFrom:
            secretKeyRef:
              key: admin-user
              name: grafana
        - name: GF_SECURITY_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              key: admin-password
              name: grafana
        - name: GF_INSTALL_PLUGINS
          valueFrom:
            configMapKeyRef:
              key: plugins
              name: grafana
        - name: GF_PATHS_DATA
          value: /var/lib/grafana/
        - name: GF_PATHS_LOGS
          value: /var/log/grafana
        - name: GF_PATHS_PLUGINS
          value: /var/lib/grafana/plugins
        - name: GF_PATHS_PROVISIONING
          value: /etc/grafana/provisioning
        image: docker.io/grafana/grafana:11.5.2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 10
          httpGet:
            path: /api/health
            port: 3000
          initialDelaySeconds: 60
          timeoutSeconds: 30
        name: grafana
        ports:
        - containerPort: 3000
          name: grafana
          protocol: TCP
        - containerPort: 9094
          name: gossip-tcp
          protocol: TCP
        - containerPort: 9094
          name: gossip-udp
          protocol: UDP
        - containerPort: 6060
          name: profiling
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3000
        resources:
          limits:
            memory: 150Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          seccompProfile:
            type: RuntimeDefault
        volumeMounts:
        - mountPath: /etc/grafana/grafana.ini
          name: config
          subPath: grafana.ini
        - mountPath: /var/lib/grafana
          name: storage
        - mountPath: /var/lib/grafana/dashboards/default
          name: dashboards-default
        - mountPath: /etc/grafana/provisioning/datasources/datasources.yaml
          name: config
          subPath: datasources.yaml
        - mountPath: /etc/grafana/provisioning/dashboards/dashboardproviders.yaml
          name: config
          subPath: dashboardproviders.yaml
      enableServiceLinks: true
      securityContext:
        fsGroup: 472
        runAsGroup: 472
        runAsNonRoot: true
        runAsUser: 472
      serviceAccountName: grafana
      shareProcessNamespace: false
      volumes:
      - configMap:
          name: grafana
        name: config
      - configMap:
          name: grafana-dashboards
        name: dashboards-default
      - emptyDir: {}
        name: storage
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: all-in-one
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: jaeger
    app.kubernetes.io/version: 1.53.0
    prometheus.io/port: '14269'
    prometheus.io/scrape: 'true'
  name: jaeger
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: all-in-one
      app.kubernetes.io/instance: opentelemetry-demo
      app.kubernetes.io/name: jaeger
  strategy:
    type: Recreate
  template:
    metadata:
      annotations:
        prometheus.io/port: '14269'
        prometheus.io/scrape: 'true'
      labels:
        app.kubernetes.io/component: all-in-one
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: jaeger
    spec:
      containers:
      - args:
        - --memory.max-traces=5000
        - --query.base-path=/jaeger/ui
        - --prometheus.server-url=http://prometheus:9090
        - --prometheus.query.normalize-calls=true
        - --prometheus.query.normalize-duration=true
        env:
        - name: METRICS_STORAGE_TYPE
          value: prometheus
        - name: COLLECTOR_OTLP_GRPC_HOST_PORT
          value: 0.0.0.0:4317
        - name: COLLECTOR_OTLP_HTTP_HOST_PORT
          value: 0.0.0.0:4318
        - name: SPAN_STORAGE_TYPE
          value: memory
        - name: COLLECTOR_ZIPKIN_HOST_PORT
          value: :9411
        - name: JAEGER_DISABLED
          value: 'false'
        - name: COLLECTOR_OTLP_ENABLED
          value: 'true'
        image: jaegertracing/all-in-one:1.53.0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /
            port: 14269
            scheme: HTTP
          initialDelaySeconds: 5
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 1
        name: jaeger
        ports:
        - containerPort: 5775
          protocol: UDP
        - containerPort: 6831
          protocol: UDP
        - containerPort: 6832
          protocol: UDP
        - containerPort: 5778
          protocol: TCP
        - containerPort: 16686
          protocol: TCP
        - containerPort: 16685
          protocol: TCP
        - containerPort: 9411
          protocol: TCP
        - containerPort: 4317
          protocol: TCP
        - containerPort: 4318
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 14269
            scheme: HTTP
          initialDelaySeconds: 1
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        resources:
          limits:
            memory: 400Mi
        securityContext: {}
        volumeMounts: null
      securityContext:
        fsGroup: 10001
        runAsGroup: 10001
        runAsUser: 10001
      serviceAccountName: jaeger
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: standalone-collector
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/version: 0.120.0
  name: otel-collector
  namespace: otel-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: opentelemetry-demo
      app.kubernetes.io/name: opentelemetry-collector
      component: standalone-collector
  strategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: a89266db0e62ae4711e3cef2ea43e19dac4d19232eb4bb06b05882a36f128110
        opentelemetry_community_demo: 'true'
        prometheus.io/scrape: 'true'
      labels:
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: opentelemetry-collector
        component: standalone-collector
    spec:
      containers:
      - args:
        - --config=/conf/relay.yaml
        env:
        - name: MY_POD_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.podIP
        - name: GOMEMLIMIT
          value: 160MiB
        image: otel/opentelemetry-collector-contrib:0.120.0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          httpGet:
            path: /
            port: 13133
        name: opentelemetry-collector
        ports:
        - containerPort: 6831
          name: jaeger-compact
          protocol: UDP
        - containerPort: 14250
          name: jaeger-grpc
          protocol: TCP
        - containerPort: 14268
          name: jaeger-thrift
          protocol: TCP
        - containerPort: 8888
          name: metrics
          protocol: TCP
        - containerPort: 4317
          name: otlp
          protocol: TCP
        - containerPort: 4318
          name: otlp-http
          protocol: TCP
        - containerPort: 9411
          name: zipkin
          protocol: TCP
        readinessProbe:
          httpGet:
            path: /
            port: 13133
        resources:
          limits:
            memory: 200Mi
        securityContext: {}
        volumeMounts:
        - mountPath: /conf
          name: opentelemetry-collector-configmap
      hostNetwork: false
      securityContext: {}
      serviceAccountName: otel-collector
      volumes:
      - configMap:
          items:
          - key: relay
            path: relay.yaml
          name: otel-collector
        name: opentelemetry-collector-configmap
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: prometheus
    app.kubernetes.io/version: v3.1.0
  name: prometheus
  namespace: otel-demo
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: opentelemetry-demo
      app.kubernetes.io/name: prometheus
  strategy:
    rollingUpdate: null
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/component: server
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: prometheus
        app.kubernetes.io/part-of: prometheus
        app.kubernetes.io/version: v3.1.0
    spec:
      containers:
      - args:
        - --storage.tsdb.retention.time=15d
        - --config.file=/etc/config/prometheus.yml
        - --storage.tsdb.path=/data
        - --web.console.libraries=/etc/prometheus/console_libraries
        - --web.console.templates=/etc/prometheus/consoles
        - --enable-feature=exemplar-storage
        - --web.enable-otlp-receiver
        image: quay.io/prometheus/prometheus:v3.1.0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /-/healthy
            port: 9090
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 10
        name: prometheus-server
        ports:
        - containerPort: 9090
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /-/ready
            port: 9090
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 4
        resources:
          limits:
            memory: 300Mi
        volumeMounts:
        - mountPath: /etc/config
          name: config-volume
        - mountPath: /data
          name: storage-volume
          subPath: ''
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      serviceAccountName: prometheus
      terminationGracePeriodSeconds: 300
      volumes:
      - configMap:
          name: prometheus
        name: config-volume
      - emptyDir: {}
        name: storage-volume
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: accounting
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: accounting
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: accounting
  name: accounting
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: accounting
  template:
    metadata:
      labels:
        app.kubernetes.io/component: accounting
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: accounting
        opentelemetry.io/name: accounting
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: KAFKA_ADDR
          value: kafka:9092
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4318
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-accounting
        imagePullPolicy: IfNotPresent
        name: accounting
        resources:
          limits:
            memory: 120Mi
        volumeMounts: null
      initContainers:
      - command:
        - sh
        - -c
        - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
        image: busybox:latest
        name: wait-for-kafka
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: ad
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: ad
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: ad
  name: ad
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: ad
  template:
    metadata:
      labels:
        app.kubernetes.io/component: ad
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: ad
        opentelemetry.io/name: ad
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: AD_PORT
          value: '8080'
        - name: FLAGD_HOST
          value: flagd
        - name: FLAGD_PORT
          value: '8013'
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4318
        - name: OTEL_LOGS_EXPORTER
          value: otlp
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-ad
        imagePullPolicy: IfNotPresent
        name: ad
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 300Mi
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: cart
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: cart
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: cart
  name: cart
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: cart
  template:
    metadata:
      labels:
        app.kubernetes.io/component: cart
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: cart
        opentelemetry.io/name: cart
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: CART_PORT
          value: '8080'
        - name: ASPNETCORE_URLS
          value: http://*:$(CART_PORT)
        - name: VALKEY_ADDR
          value: valkey-cart:6379
        - name: FLAGD_HOST
          value: flagd
        - name: FLAGD_PORT
          value: '8013'
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4317
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-cart
        imagePullPolicy: IfNotPresent
        name: cart
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 160Mi
        volumeMounts: null
      initContainers:
      - command:
        - sh
        - -c
        - until nc -z -v -w30 valkey-cart 6379; do echo waiting for valkey-cart; sleep
          2; done;
        image: busybox:latest
        name: wait-for-valkey-cart
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: checkout
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: checkout
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: checkout
  name: checkout
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: checkout
  template:
    metadata:
      labels:
        app.kubernetes.io/component: checkout
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: checkout
        opentelemetry.io/name: checkout
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: CHECKOUT_PORT
          value: '8080'
        - name: CART_ADDR
          value: cart:8080
        - name: CURRENCY_ADDR
          value: currency:8080
        - name: EMAIL_ADDR
          value: http://email:8080
        - name: PAYMENT_ADDR
          value: payment:8080
        - name: PRODUCT_CATALOG_ADDR
          value: product-catalog:8080
        - name: SHIPPING_ADDR
          value: shipping:8080
        - name: KAFKA_ADDR
          value: kafka:9092
        - name: FLAGD_HOST
          value: flagd
        - name: FLAGD_PORT
          value: '8013'
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4317
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-checkout
        imagePullPolicy: IfNotPresent
        name: checkout
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 20Mi
        volumeMounts: null
      initContainers:
      - command:
        - sh
        - -c
        - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
        image: busybox:latest
        name: wait-for-kafka
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: currency
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: currency
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: currency
  name: currency
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: currency
  template:
    metadata:
      labels:
        app.kubernetes.io/component: currency
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: currency
        opentelemetry.io/name: currency
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: CURRENCY_PORT
          value: '8080'
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4317
        - name: VERSION
          value: 2.0.2
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-currency
        imagePullPolicy: IfNotPresent
        name: currency
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 20Mi
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: email
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: email
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: email
  name: email
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: email
  template:
    metadata:
      labels:
        app.kubernetes.io/component: email
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: email
        opentelemetry.io/name: email
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: EMAIL_PORT
          value: '8080'
        - name: APP_ENV
          value: production
        - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4318/v1/traces
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-email
        imagePullPolicy: IfNotPresent
        name: email
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 100Mi
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: flagd
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: flagd
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: flagd
  name: flagd
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: flagd
  template:
    metadata:
      labels:
        app.kubernetes.io/component: flagd
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: flagd
        opentelemetry.io/name: flagd
    spec:
      containers:
      - command:
        - /flagd-build
        - start
        - --port
        - '8013'
        - --ofrep-port
        - '8016'
        - --uri
        - file:./etc/flagd/demo.flagd.json
        env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: FLAGD_METRICS_EXPORTER
          value: otel
        - name: FLAGD_OTEL_COLLECTOR_URI
          value: $(OTEL_COLLECTOR_NAME):4317
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-feature/flagd:v0.11.1
        imagePullPolicy: IfNotPresent
        name: flagd
        ports:
        - containerPort: 8013
          name: rpc
        - containerPort: 8016
          name: ofrep
        resources:
          limits:
            memory: 75Mi
        volumeMounts:
        - mountPath: /etc/flagd
          name: config-rw
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: FLAGD_METRICS_EXPORTER
          value: otel
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4318
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-flagd-ui
        imagePullPolicy: IfNotPresent
        name: flagd-ui
        ports:
        - containerPort: 4000
          name: service
        resources:
          limits:
            memory: 100Mi
        volumeMounts:
        - mountPath: /app/data
          name: config-rw
      initContainers:
      - command:
        - sh
        - -c
        - cp /config-ro/demo.flagd.json /config-rw/demo.flagd.json && cat /config-rw/demo.flagd.json
        image: busybox
        name: init-config
        volumeMounts:
        - mountPath: /config-ro
          name: config-ro
        - mountPath: /config-rw
          name: config-rw
      serviceAccountName: opentelemetry-demo
      volumes:
      - emptyDir: {}
        name: config-rw
      - configMap:
          name: flagd-config
        name: config-ro
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: fraud-detection
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: fraud-detection
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: fraud-detection
  name: fraud-detection
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: fraud-detection
  template:
    metadata:
      labels:
        app.kubernetes.io/component: fraud-detection
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: fraud-detection
        opentelemetry.io/name: fraud-detection
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: KAFKA_ADDR
          value: kafka:9092
        - name: FLAGD_HOST
          value: flagd
        - name: FLAGD_PORT
          value: '8013'
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4318
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-fraud-detection
        imagePullPolicy: IfNotPresent
        name: fraud-detection
        resources:
          limits:
            memory: 300Mi
        volumeMounts: null
      initContainers:
      - command:
        - sh
        - -c
        - until nc -z -v -w30 kafka 9092; do echo waiting for kafka; sleep 2; done;
        image: busybox:latest
        name: wait-for-kafka
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: frontend
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: frontend
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: frontend
  name: frontend
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: frontend
  template:
    metadata:
      labels:
        app.kubernetes.io/component: frontend
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: frontend
        opentelemetry.io/name: frontend
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: FRONTEND_PORT
          value: '8080'
        - name: FRONTEND_ADDR
          value: :8080
        - name: AD_ADDR
          value: ad:8080
        - name: CART_ADDR
          value: cart:8080
        - name: CHECKOUT_ADDR
          value: checkout:8080
        - name: CURRENCY_ADDR
          value: currency:8080
        - name: PRODUCT_CATALOG_ADDR
          value: product-catalog:8080
        - name: RECOMMENDATION_ADDR
          value: recommendation:8080
        - name: SHIPPING_ADDR
          value: shipping:8080
        - name: FLAGD_HOST
          value: flagd
        - name: FLAGD_PORT
          value: '8013'
        - name: OTEL_COLLECTOR_HOST
          value: $(OTEL_COLLECTOR_NAME)
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4317
        - name: WEB_OTEL_SERVICE_NAME
          value: frontend-web
        - name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
          value: http://localhost:8080/otlp-http/v1/traces
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-frontend
        imagePullPolicy: IfNotPresent
        name: frontend
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 250Mi
        securityContext:
          runAsGroup: 1001
          runAsNonRoot: true
          runAsUser: 1001
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: frontend-proxy
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: frontend-proxy
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: frontend-proxy
  name: frontend-proxy
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: frontend-proxy
  template:
    metadata:
      labels:
        app.kubernetes.io/component: frontend-proxy
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: frontend-proxy
        opentelemetry.io/name: frontend-proxy
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: ENVOY_PORT
          value: '8080'
        - name: FLAGD_HOST
          value: flagd
        - name: FLAGD_PORT
          value: '8013'
        - name: FLAGD_UI_HOST
          value: flagd
        - name: FLAGD_UI_PORT
          value: '4000'
        - name: FRONTEND_HOST
          value: frontend
        - name: FRONTEND_PORT
          value: '8080'
        - name: GRAFANA_HOST
          value: grafana
        - name: GRAFANA_PORT
          value: '80'
        - name: IMAGE_PROVIDER_HOST
          value: image-provider
        - name: IMAGE_PROVIDER_PORT
          value: '8081'
        - name: JAEGER_HOST
          value: jaeger-query
        - name: JAEGER_PORT
          value: '16686'
        - name: LOCUST_WEB_HOST
          value: load-generator
        - name: LOCUST_WEB_PORT
          value: '8089'
        - name: OTEL_COLLECTOR_HOST
          value: $(OTEL_COLLECTOR_NAME)
        - name: OTEL_COLLECTOR_PORT_GRPC
          value: '4317'
        - name: OTEL_COLLECTOR_PORT_HTTP
          value: '4318'
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-frontend-proxy
        imagePullPolicy: IfNotPresent
        name: frontend-proxy
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 65Mi
        securityContext:
          runAsGroup: 101
          runAsNonRoot: true
          runAsUser: 101
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: image-provider
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: image-provider
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: image-provider
  name: image-provider
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: image-provider
  template:
    metadata:
      labels:
        app.kubernetes.io/component: image-provider
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: image-provider
        opentelemetry.io/name: image-provider
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: IMAGE_PROVIDER_PORT
          value: '8081'
        - name: OTEL_COLLECTOR_PORT_GRPC
          value: '4317'
        - name: OTEL_COLLECTOR_HOST
          value: $(OTEL_COLLECTOR_NAME)
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-image-provider
        imagePullPolicy: IfNotPresent
        name: image-provider
        ports:
        - containerPort: 8081
          name: service
        resources:
          limits:
            memory: 50Mi
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: kafka
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: kafka
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: kafka
  name: kafka
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: kafka
  template:
    metadata:
      labels:
        app.kubernetes.io/component: kafka
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: kafka
        opentelemetry.io/name: kafka
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: KAFKA_ADVERTISED_LISTENERS
          value: PLAINTEXT://kafka:9092
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4318
        - name: KAFKA_HEAP_OPTS
          value: -Xmx400M -Xms400M
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-kafka
        imagePullPolicy: IfNotPresent
        name: kafka
        ports:
        - containerPort: 9092
          name: plaintext
        - containerPort: 9093
          name: controller
        resources:
          limits:
            memory: 600Mi
        securityContext:
          runAsGroup: 1000
          runAsNonRoot: true
          runAsUser: 1000
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: load-generator
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: load-generator
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: load-generator
  name: load-generator
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: load-generator
  template:
    metadata:
      labels:
        app.kubernetes.io/component: load-generator
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: load-generator
        opentelemetry.io/name: load-generator
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: LOCUST_WEB_HOST
          value: 0.0.0.0
        - name: LOCUST_WEB_PORT
          value: '8089'
        - name: LOCUST_USERS
          value: '10'
        - name: LOCUST_SPAWN_RATE
          value: '1'
        - name: LOCUST_HOST
          value: http://frontend-proxy:8080
        - name: LOCUST_HEADLESS
          value: 'false'
        - name: LOCUST_AUTOSTART
          value: 'true'
        - name: LOCUST_BROWSER_TRAFFIC_ENABLED
          value: 'true'
        - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
          value: python
        - name: FLAGD_HOST
          value: flagd
        - name: FLAGD_OFREP_PORT
          value: '8016'
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4317
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-load-generator
        imagePullPolicy: IfNotPresent
        name: load-generator
        ports:
        - containerPort: 8089
          name: service
        resources:
          limits:
            memory: 1500Mi
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: payment
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: payment
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: payment
  name: payment
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: payment
  template:
    metadata:
      labels:
        app.kubernetes.io/component: payment
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: payment
        opentelemetry.io/name: payment
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: PAYMENT_PORT
          value: '8080'
        - name: FLAGD_HOST
          value: flagd
        - name: FLAGD_PORT
          value: '8013'
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4317
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-payment
        imagePullPolicy: IfNotPresent
        name: payment
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 120Mi
        securityContext:
          runAsGroup: 1000
          runAsNonRoot: true
          runAsUser: 1000
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: product-catalog
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: product-catalog
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: product-catalog
  name: product-catalog
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: product-catalog
  template:
    metadata:
      labels:
        app.kubernetes.io/component: product-catalog
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: product-catalog
        opentelemetry.io/name: product-catalog
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: PRODUCT_CATALOG_PORT
          value: '8080'
        - name: PRODUCT_CATALOG_RELOAD_INTERVAL
          value: '10'
        - name: FLAGD_HOST
          value: flagd
        - name: FLAGD_PORT
          value: '8013'
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4317
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-product-catalog
        imagePullPolicy: IfNotPresent
        name: product-catalog
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 20Mi
        volumeMounts:
        - mountPath: /usr/src/app/products
          name: product-catalog-products
      serviceAccountName: opentelemetry-demo
      volumes:
      - configMap:
          name: product-catalog-products
        name: product-catalog-products
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: quote
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: quote
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: quote
  name: quote
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: quote
  template:
    metadata:
      labels:
        app.kubernetes.io/component: quote
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: quote
        opentelemetry.io/name: quote
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: QUOTE_PORT
          value: '8080'
        - name: OTEL_PHP_AUTOLOAD_ENABLED
          value: 'true'
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4318
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-quote
        imagePullPolicy: IfNotPresent
        name: quote
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 40Mi
        securityContext:
          runAsGroup: 33
          runAsNonRoot: true
          runAsUser: 33
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: recommendation
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: recommendation
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: recommendation
  name: recommendation
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: recommendation
  template:
    metadata:
      labels:
        app.kubernetes.io/component: recommendation
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: recommendation
        opentelemetry.io/name: recommendation
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: RECOMMENDATION_PORT
          value: '8080'
        - name: PRODUCT_CATALOG_ADDR
          value: product-catalog:8080
        - name: OTEL_PYTHON_LOG_CORRELATION
          value: 'true'
        - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
          value: python
        - name: FLAGD_HOST
          value: flagd
        - name: FLAGD_PORT
          value: '8013'
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4317
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-recommendation
        imagePullPolicy: IfNotPresent
        name: recommendation
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 500Mi
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: shipping
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: shipping
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: shipping
  name: shipping
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: shipping
  template:
    metadata:
      labels:
        app.kubernetes.io/component: shipping
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: shipping
        opentelemetry.io/name: shipping
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: SHIPPING_PORT
          value: '8080'
        - name: QUOTE_ADDR
          value: http://quote:8080
        - name: OTEL_EXPORTER_OTLP_ENDPOINT
          value: http://$(OTEL_COLLECTOR_NAME):4317
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: ghcr.io/open-telemetry/demo:2.0.2-shipping
        imagePullPolicy: IfNotPresent
        name: shipping
        ports:
        - containerPort: 8080
          name: service
        resources:
          limits:
            memory: 20Mi
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: valkey-cart
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: valkey-cart
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/version: 2.0.2
    opentelemetry.io/name: valkey-cart
  name: valkey-cart
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      opentelemetry.io/name: valkey-cart
  template:
    metadata:
      labels:
        app.kubernetes.io/component: valkey-cart
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: valkey-cart
        opentelemetry.io/name: valkey-cart
    spec:
      containers:
      - env:
        - name: OTEL_SERVICE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.labels['app.kubernetes.io/component']
        - name: OTEL_COLLECTOR_NAME
          value: otel-collector
        - name: OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
          value: cumulative
        - name: OTEL_RESOURCE_ATTRIBUTES
          value: service.name=$(OTEL_SERVICE_NAME),service.namespace=opentelemetry-demo,service.version=2.0.2
        image: valkey/valkey:7.2-alpine
        imagePullPolicy: IfNotPresent
        name: valkey-cart
        ports:
        - containerPort: 6379
          name: valkey-cart
        resources:
          limits:
            memory: 20Mi
        securityContext:
          runAsGroup: 1000
          runAsNonRoot: true
          runAsUser: 999
        volumeMounts: null
      serviceAccountName: opentelemetry-demo
      volumes: null
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    majorVersion: '2'
  labels:
    app.kubernetes.io/component: opensearch
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opensearch
    app.kubernetes.io/version: 2.19.0
  name: opensearch
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: opentelemetry-demo
      app.kubernetes.io/name: opensearch
  serviceName: opensearch-headless
  template:
    metadata:
      annotations:
        configchecksum: 39d5e484f1cc28f685f786a856c4336341c6c034f5c0b1a81337e4a39511e47
      labels:
        app.kubernetes.io/component: opensearch
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/name: opensearch
        app.kubernetes.io/version: 2.19.0
      name: opensearch
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app.kubernetes.io/instance
                  operator: In
                  values:
                  - opentelemetry-demo
                - key: app.kubernetes.io/name
                  operator: In
                  values:
                  - opensearch
              topologyKey: kubernetes.io/hostname
            weight: 1
      automountServiceAccountToken: false
      containers:
      - env:
        - name: node.name
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: discovery.seed_hosts
          value: opensearch-cluster-master-headless
        - name: cluster.name
          value: demo-cluster
        - name: network.host
          value: 0.0.0.0
        - name: OPENSEARCH_JAVA_OPTS
          value: -Xms300m -Xmx300m
        - name: node.roles
          value: master,ingest,data,remote_cluster_client,
        - name: discovery.type
          value: single-node
        - name: bootstrap.memory_lock
          value: 'true'
        - name: DISABLE_INSTALL_DEMO_CONFIG
          value: 'true'
        - name: DISABLE_SECURITY_PLUGIN
          value: 'true'
        image: opensearchproject/opensearch:2.19.0
        imagePullPolicy: IfNotPresent
        name: opensearch
        ports:
        - containerPort: 9200
          name: http
        - containerPort: 9300
          name: transport
        - containerPort: 9600
          name: metrics
        readinessProbe:
          failureThreshold: 3
          periodSeconds: 5
          tcpSocket:
            port: 9200
          timeoutSeconds: 3
        resources:
          limits:
            memory: 1100Mi
          requests:
            cpu: 1000m
            memory: 100Mi
        securityContext:
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
        startupProbe:
          failureThreshold: 30
          initialDelaySeconds: 5
          periodSeconds: 10
          tcpSocket:
            port: 9200
          timeoutSeconds: 3
        volumeMounts:
        - mountPath: /usr/share/opensearch/config/opensearch.yml
          name: config-emptydir
          subPath: opensearch.yml
      enableServiceLinks: true
      initContainers:
      - command:
        - sh
        - -c
        - '#!/usr/bin/env bash

          cp -r /tmp/configfolder/*  /tmp/config/

          '
        image: opensearchproject/opensearch:2.19.0
        imagePullPolicy: IfNotPresent
        name: configfile
        resources: {}
        volumeMounts:
        - mountPath: /tmp/config/
          name: config-emptydir
        - mountPath: /tmp/configfolder/opensearch.yml
          name: config
          subPath: opensearch.yml
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      terminationGracePeriodSeconds: 120
      volumes:
      - configMap:
          name: opensearch-config
        name: config
      - emptyDir: {}
        name: config-emptydir
  updateStrategy:
    type: RollingUpdate
